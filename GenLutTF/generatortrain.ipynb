{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagegenerator import HDR2SDRImageGenerator\n",
    "from multicsvreader import MultiCSVReader\n",
    "from lutmaker import predict, write_lut_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_map = []\n",
    "# imapf = open(\"../pyfilemap.txt\", \"r\")\n",
    "\n",
    "# # s07e01 = 1091612160\n",
    "# # s07e02 = 1075912320\n",
    "# # s07e03 = 828664320\n",
    "\n",
    "# hdr = None\n",
    "# for line in imapf:\n",
    "#     if hdr is None:\n",
    "#         hdr = line.strip()\n",
    "#     else:\n",
    "#         image_map.append((hdr, line.strip()))\n",
    "#         hdr = None\n",
    "\n",
    "# imapf.close()\n",
    "\n",
    "# random.shuffle(image_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_gen = HDR2SDRImageGenerator(\n",
    "#     image_map,\n",
    "#     image_size=(1920, 1080),\n",
    "#     batch_size=2048,\n",
    "#     crop=(0, 0, 132, 132),\n",
    "#     buffer_size=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_types = {\n",
    "    'hr': np.uint16,\n",
    "    'hg': np.uint16,\n",
    "    'hb': np.uint16,\n",
    "    'sr': np.uint8,\n",
    "    'sg': np.uint8,\n",
    "    'sb': np.uint8,\n",
    "}\n",
    "\n",
    "csv_files = [\n",
    "    's07e01_1', \n",
    "    's07e02_1', \n",
    "    's07e03_1', \n",
    "    's07e04_1', \n",
    "#     's07e05_1', \n",
    "]\n",
    "csv_files = [f\"../data/{s}.xz\" for s in csv_files]\n",
    "\n",
    "\n",
    "csv_file_sizes = [1091612160, 1075912320, 828664320, 1058580480]\n",
    "\n",
    "image_gen = MultiCSVReader(\n",
    "    csv_list=csv_files,\n",
    "    csv_sizes=csv_file_sizes,\n",
    "    batch_size=2048,\n",
    "    csv_dtypes=csv_types,\n",
    "    x_cols=['hr', 'hg', 'hb'],\n",
    "    y_cols=['sr', 'sg', 'sb']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp():\n",
    "    return str(int(time.time()))\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(32, activation=tf.nn.relu, input_shape=[3]),\n",
    "        layers.Dense(32, activation=tf.nn.relu),\n",
    "        layers.Dense(3)\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
    "    \n",
    "    # loss: mean_squared_error or mean_absolute_error\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cp_filepath = \"../checkpoints/weights-\" + timestamp() + \"-{loss:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(cp_filepath, monitor='loss')\n",
    "\n",
    "model.fit(image_gen, epochs=1, callbacks=[checkpoint], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and output LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, 65535, 61937, 771) # The yellow of the CW logo - should be (133, 132, 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_lut_fast(\"../generated_lut.cube\", model, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
