{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_types = {\n",
    "    'hr': np.uint16,\n",
    "    'hg': np.uint16,\n",
    "    'hb': np.uint16,\n",
    "    'sr': np.uint8,\n",
    "    'sg': np.uint8,\n",
    "    'sb': np.uint8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(32, activation=tf.nn.relu, input_shape=[3]),\n",
    "        layers.Dense(32, activation=tf.nn.relu),\n",
    "        layers.Dense(3)\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
    "    \n",
    "    # loss: mean_squared_error or mean_absolute_error\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp():\n",
    "    return str(int(time.time()))\n",
    "\n",
    "def train_model_on(model, file_path):\n",
    "    \n",
    "    # load x and y from csv\n",
    "    csv_data = pd.read_csv(file_path, dtype=csv_types)\n",
    "    x_train = csv_data[['hr', 'hg', 'hb']]\n",
    "    y_train = csv_data[['sr', 'sg', 'sb']]\n",
    "    shuffle_buffer_size = len(x_train) // 48\n",
    "    \n",
    "    # load into tensorflow\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_train.values, y_train.values))\n",
    "    \n",
    "    # deallocate pandas data\n",
    "    csv_data = None\n",
    "    x_train = None\n",
    "    y_train = None\n",
    "    \n",
    "    # shuffle and batch\n",
    "    train_dataset = dataset.shuffle(shuffle_buffer_size).batch(2048)\n",
    "    \n",
    "    # deallocate old tf dataset\n",
    "    dataset = None\n",
    "    \n",
    "    # configure checkpoints - will save weights after epochs\n",
    "    cp_filepath = \"../checkpoints/weights-\" + timestamp() + \"-{loss:.2f}.hdf5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(cp_filepath, monitor='loss')\n",
    "    \n",
    "    # train the model\n",
    "    model.fit(train_dataset, epochs=1, callbacks=[checkpoint])\n",
    "    \n",
    "    # deallocate training dateset\n",
    "    train_dataset = None\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [\n",
    "    's07e01_1', 's07e01_2', 's07e01_3', 's07e01_4',\n",
    "    's07e02_1', 's07e02_2', 's07e02_3', 's07e02_4',\n",
    "#     's07e03_1', 's07e03_2', 's07e03_3', 's07e03_4',\n",
    "#     's07e04_1', 's07e04_2', 's07e04_3', 's07e04_4',\n",
    "]\n",
    "csv_files = [f\"../data/{s}.xz\" for s in csv_files]\n",
    "random.shuffle(csv_files)\n",
    "\n",
    "TEMP_WEIGHTS_FILE = '../checkpoints/temp.hdf5'\n",
    "\n",
    "model = build_model()\n",
    "display(model.summary())\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    print(f\"Training on: {csv_file}\")\n",
    "    train_model_on(model, csv_file)\n",
    "    model.save_weights(TEMP_WEIGHTS_FILE)\n",
    "    model = None\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = build_model()\n",
    "    model.load_weights(TEMP_WEIGHTS_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(hr, hg, hb):\n",
    "    tf_in = tf.convert_to_tensor([[hr, hg, hb]])\n",
    "    sdr_out = model.predict(tf_in)\n",
    "    sr, sg, sb = sdr_out[0]\n",
    "    sr = np.clip(sr, 0.0, 255.0)\n",
    "    sg = np.clip(sg, 0.0, 255.0)\n",
    "    sb = np.clip(sb, 0.0, 255.0)\n",
    "    return sr, sg, sb\n",
    "\n",
    "def batch_predict(lst):\n",
    "    tf_in = tf.convert_to_tensor(lst)\n",
    "    return batch_predict_tf(tf_in)\n",
    "\n",
    "def batch_predict_tf(tf_in):\n",
    "    sdr_out = model.predict(tf_in)\n",
    "    return np.clip(sdr_out, 0.0, 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usually 17, 35, or 65. 129 doesn't work in some ffmpeg builds\n",
    "lut_size = 129\n",
    "\n",
    "lut_step_size = 65535.0 / lut_size\n",
    "\n",
    "def luti_to_hdr(i):\n",
    "    return lut_step_size * i\n",
    "\n",
    "def sdr_to_lutv(c):\n",
    "    return c / 255.0\n",
    "\n",
    "def write_lut_fast():\n",
    "    lut_file = open(\"../generated_lut.cube\", \"w+\")\n",
    "    lut_file.write(\"TITLE \\\"HDR_2_SDR_generated_lut\\\"\")\n",
    "    lut_file.write(\"\\n\")\n",
    "    lut_file.write(\"LUT_3D_SIZE \" + str(lut_size))\n",
    "    lut_file.write(\"\\n\")\n",
    "    for bi in range(0, lut_size):\n",
    "        for gi in range(0, lut_size):\n",
    "            ril = list(range(0, lut_size))\n",
    "            hdr_list = [[luti_to_hdr(ri), luti_to_hdr(gi), luti_to_hdr(bi)] for ri in ril]\n",
    "            prediction_list = batch_predict(hdr_list)\n",
    "            for sr, sg, sb in prediction_list:\n",
    "                lr, lg, lb = sdr_to_lutv(sr), sdr_to_lutv(sg), sdr_to_lutv(sb)\n",
    "                lut_file.write(f\"{lr:.6f} {lg:.6f} {lb:.6f}\")\n",
    "                lut_file.write(\"\\n\")\n",
    "    lut_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_lut_fast()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
